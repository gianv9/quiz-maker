#!/usr/bin/env python3
"""
Convenient test runner script for the quiz application.

Usage:
    python run_tests.py              # Run all tests
    python run_tests.py --fast       # Run tests without coverage
    python run_tests.py --coverage   # Run with detailed coverage
    python run_tests.py --unit       # Run only unit tests
    python run_tests.py --routes     # Run only route tests
    python run_tests.py --e2e        # Run end-to-end tests with emulator
    python run_tests.py --all        # Run unit tests + e2e tests
"""

import subprocess
import sys
import os
import time
import json
import requests
from pathlib import Path

def run_command(cmd, capture_output=False):
    """Run a command and return the result."""
    print(f"Running: {' '.join(cmd)}")
    result = subprocess.run(cmd, capture_output=capture_output, text=True)
    return result.returncode, result.stdout, result.stderr

def check_firebase_project():
    """Check if we're in a Firebase project directory."""
    # In CI, use environment variable
    if os.environ.get('CI') == 'true':
        project_id = os.environ.get('GOOGLE_CLOUD_PROJECT', 'quiz-maker-test')
        print(f"‚úÖ Firebase project (CI): {project_id}")
        return project_id
    
    # Check current directory first
    firebaserc_path = Path('.firebaserc')
    if not firebaserc_path.exists():
        # Check parent directory (functions folder case)
        firebaserc_path = Path('../.firebaserc')
        if not firebaserc_path.exists():
            print("‚ùå No .firebaserc found. Make sure you're in a Firebase project directory.")
            return False
    
    try:
        with open(firebaserc_path, 'r') as f:
            config = json.load(f)
            project_id = config.get('projects', {}).get('default')
            if project_id:
                print(f"‚úÖ Firebase project: {project_id}")
                return project_id
    except Exception as e:
        print(f"‚ùå Error reading .firebaserc: {e}")
    return False

def start_emulator():
    """Start Firebase emulator and wait for it to be ready."""
    print("üöÄ Starting Firebase emulator...")
    
    # Check if we're in CI environment
    is_ci = os.environ.get('CI') == 'true'
    
    # Start emulator in background
    cmd = ['firebase', 'emulators:start', '--only', 'functions']
    if is_ci:
        cmd.extend(['--project', 'quiz-maker-test'])
    
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    
    # Wait for emulator to be ready
    max_attempts = 60 if is_ci else 30  # More time in CI
    for attempt in range(max_attempts):
        try:
            response = requests.get('http://127.0.0.1:4000', timeout=3)
            if response.status_code == 200:
                print("‚úÖ Emulator is ready!")
                time.sleep(2)  # Extra wait for stability
                return process
        except:
            pass
        
        print(f"‚è≥ Waiting for emulator... ({attempt + 1}/{max_attempts})")
        time.sleep(3 if is_ci else 2)  # Longer waits in CI
    
    print("‚ùå Emulator failed to start")
    if process.poll() is None:
        process.terminate()
        process.wait()
    return None

def test_endpoints(project_id):
    """Test all API endpoints."""
    base_url = f"http://127.0.0.1:5001/{project_id}/us-central1/api"
    
    tests = [
        {
            'name': 'Get Topics',
            'method': 'GET',
            'url': f"{base_url}/",
            'expected_type': list
        },
        {
            'name': 'Get Questions',
            'method': 'GET', 
            'url': f"{base_url}/questions/python/easy",
            'expected_type': list
        },
        {
            'name': 'Get Results',
            'method': 'GET',
            'url': f"{base_url}/results", 
            'expected_type': list
        },
        {
            'name': 'Submit Score',
            'method': 'POST',
            'url': f"{base_url}/submit-score",
            'data': {
                'topic': 'python',
                'difficulty': 'easy', 
                'score': 80,
                'correct': 4,
                'total': 5
            },
            'expected_type': dict
        }
    ]
    
    results = []
    print("\nüß™ Testing API endpoints...")
    
    for test in tests:
        print(f"\nüì° Testing: {test['name']}")
        try:
            if test['method'] == 'GET':
                response = requests.get(test['url'], timeout=10)
            else:
                response = requests.post(
                    test['url'], 
                    json=test['data'], 
                    timeout=10,
                    headers={'Content-Type': 'application/json'}
                )
            
            if response.status_code == 200:
                data = response.json()
                if isinstance(data, test['expected_type']):
                    print(f"   ‚úÖ {test['name']}: Success")
                    print(f"   üìÑ Response: {str(data)[:100]}...")
                    results.append((test['name'], True, None))
                else:
                    print(f"   ‚ö†Ô∏è  {test['name']}: Wrong response type")
                    results.append((test['name'], False, f"Expected {test['expected_type']}, got {type(data)}"))
            else:
                print(f"   ‚ùå {test['name']}: HTTP {response.status_code}")
                results.append((test['name'], False, f"HTTP {response.status_code}"))
                
        except requests.exceptions.Timeout:
            print(f"   ‚ö†Ô∏è  {test['name']}: Timeout (emulator issue)")
            results.append((test['name'], False, "Timeout"))
        except Exception as e:
            print(f"   ‚ùå {test['name']}: {str(e)}")
            results.append((test['name'], False, str(e)))
    
    return results

def run_e2e_tests():
    """Run end-to-end tests with Firebase emulator."""
    print("üéØ Running End-to-End Tests")
    print("=" * 50)
    
    # Check if we're in the right directory
    project_id = check_firebase_project()
    if not project_id:
        return 1
    
    # Start emulator
    emulator_process = start_emulator()
    if not emulator_process:
        return 1
    
    try:
        # Test endpoints
        results = test_endpoints(project_id)
        
        # Print summary
        print("\nüìä Test Summary:")
        print("-" * 30)
        passed = sum(1 for _, success, _ in results if success)
        total = len(results)
        
        for name, success, error in results:
            status = "‚úÖ PASS" if success else f"‚ùå FAIL ({error})"
            print(f"  {name:<20} {status}")
        
        print(f"\nüéØ Results: {passed}/{total} tests passed")
        
        if passed == total:
            print("üéâ All end-to-end tests passed!")
            return 0
        else:
            print("‚ö†Ô∏è  Some tests failed (may be due to emulator limitations)")
            return 0  # Don't fail on emulator timeouts
            
    finally:
        # Stop emulator
        print("\nüõë Stopping emulator...")
        emulator_process.terminate()
        emulator_process.wait()

def main():
    # Ensure we're in the right directory
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    
    if len(sys.argv) > 1:
        option = sys.argv[1]
        
        if option == "--fast":
            # Fast tests without coverage
            cmd = ["python", "-m", "pytest", "tests/", "-v"]
            
        elif option == "--coverage":
            # Detailed coverage with HTML report
            cmd = ["python", "-m", "pytest", "tests/", "-v", 
                   "--cov=app", "--cov=main", 
                   "--cov-report=html", "--cov-report=term-missing"]
            
        elif option == "--unit":
            # Only business logic tests
            cmd = ["python", "-m", "pytest", "tests/test_services.py", "-v"]
            
        elif option == "--routes":
            # Only API endpoint tests
            cmd = ["python", "-m", "pytest", "tests/test_routes.py", "-v"]
            
        elif option == "--e2e":
            # End-to-end tests with emulator
            return run_e2e_tests()
            
        elif option == "--all":
            # Run unit tests first, then e2e tests
            print("üéØ Running Complete Test Suite")
            print("=" * 50)
            
            print("\n1Ô∏è‚É£ Running Unit Tests...")
            exit_code, _, _ = run_command([
                "python", "-m", "pytest", "tests/", "-v", 
                "--cov=app", "--cov=main", "--cov-report=term-missing"
            ])
            
            if exit_code != 0:
                print("‚ùå Unit tests failed!")
                return exit_code
                
            print("\n2Ô∏è‚É£ Running End-to-End Tests...")
            return run_e2e_tests()
            
        else:
            print("Unknown option. Use --fast, --coverage, --unit, --routes, --e2e, or --all")
            return 1
    else:
        # Default: run all tests with basic coverage
        cmd = ["python", "-m", "pytest", "tests/", "-v", "--cov=app", "--cov=main"]
    
    exit_code, _, _ = run_command(cmd)
    return exit_code

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)